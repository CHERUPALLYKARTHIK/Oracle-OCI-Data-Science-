# ğŸ† My Learnings from OCI Data Science Professional Course

I recently completed the **Oracle Cloud Infrastructure (OCI) Data Science Professional** course as part of the **Oracle Race to Certification** program ğŸ“.  
This course was a complete journey through the **ML lifecycle on OCI** â€” from setting up a workspace, preparing data, training models, all the way to deploying them in production and monitoring them.  

---

## ğŸ“œ Progress 

(![OCI Data Science Professional Progress](OCI%20DS%20PROGRESS.jpg)

---

## ğŸ“– About the Course

This course taught me how to:
- ğŸ”§ Configure and manage OCI Data Science **workspaces & projects**  
- ğŸ§  Build, train, and deploy machine learning models  
- âš™ï¸ Automate workflows using **MLOps best practices**  
- ğŸ” Integrate OCI services like **Vault**, **Object Storage**, **Data Flow**, and **Data Labeling**  
- ğŸ“Š Monitor models in production and retrain them when performance drops  

---

## ğŸ’¡ What I Learned (My Key Takeaways)

### 1ï¸âƒ£ OCI Data Science Environment
- Learned how to create & manage **workspaces and projects** ğŸ—‚ï¸  
- Set up **user roles** and secure network access ğŸ”  
- Used **ADS SDK** to load data quickly and prepare it for modeling  
**Example:** Connected an Object Storage bucket and pulled data straight into a Jupyter notebook using `ads.dataset.factory`. Felt very smooth!

---

### 2ï¸âƒ£ Machine Learning Lifecycle on OCI
- ğŸ§¹ **Data Prep:** cleaned, transformed, and engineered features  
- ğŸ¤– **Training:** built models with XGBoost & scikit-learn  
- âœ… **Evaluation:** checked accuracy, ROC-AUC, and validated results  
- ğŸš€ **Deployment:** exposed models as REST endpoints for live predictions  
**Example:** Built a churn prediction model, deployed it, and tested predictions right from the notebook â€” super cool!

---

### 3ï¸âƒ£ MLOps & Automation
- Built **pipelines** that retrain models automatically when new data arrives  
- Set up **model monitoring** to catch accuracy drops ğŸ“‰  
- Learned how to version models and keep workflows reproducible  
**Example:** Configured a monitoring job that triggers an alert if model accuracy goes below a certain threshold.

---

### 4ï¸âƒ£ OCI Service Integrations
- ğŸ” **OCI Vault** â€“ managed keys & secrets safely  
- â˜ï¸ **Object Storage** â€“ stored data and model artifacts  
- âš¡ **OCI Data Flow** â€“ ran big data prep jobs at scale  
- ğŸ·ï¸ **OCI Data Labeling** â€“ created labeled datasets for training  
This gave me confidence in building a **secure, production-ready ML pipeline**.

---

### 5ï¸âƒ£ Best Practices & Business Use
- Learned **cloud security best practices** (IAM, encryption, access control)  
- Optimized for **scalability & cost** using flexible compute options  
- Mapped ML solutions to **real business problems** like churn prediction, forecasting, and NLP  

---

## ğŸš€ Why This Matters

This was not just theory â€” it was fully **hands-on**.  
Now I can:
- Build **end-to-end ML pipelines** on OCI  
- Automate retraining and monitoring with MLOps ğŸ› ï¸  
- Deliver **real-world solutions** for businesses with confidence  

---

## ğŸ›  Tech & Tools I Used
`OCI Data Science Workspaces`, `ADS SDK`, `XGBoost`, `scikit-learn`,  
`OCI Vault`, `Object Storage`, `Data Flow`, `Data Labeling`,  
`OCI Logging & Monitoring`, `REST APIs` for model deployment

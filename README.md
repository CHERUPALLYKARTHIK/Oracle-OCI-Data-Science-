# 🏆 My Learnings from OCI Data Science Professional Course

I recently completed the **Oracle Cloud Infrastructure (OCI) Data Science Professional** course as part of the **Oracle Race to Certification** program 🎓.  
This course was a complete journey through the **ML lifecycle on OCI** — from setting up a workspace, preparing data, training models, all the way to deploying them in production and monitoring them.  

---

## 📜 Progress 

(![OCI Data Science Professional Progress](OCI%20DS%20PROGRESS.jpg)

---

## 📖 About the Course

This course taught me how to:
- 🔧 Configure and manage OCI Data Science **workspaces & projects**  
- 🧠 Build, train, and deploy machine learning models  
- ⚙️ Automate workflows using **MLOps best practices**  
- 🔐 Integrate OCI services like **Vault**, **Object Storage**, **Data Flow**, and **Data Labeling**  
- 📊 Monitor models in production and retrain them when performance drops  

---

## 💡 What I Learned (My Key Takeaways)

### 1️⃣ OCI Data Science Environment
- Learned how to create & manage **workspaces and projects** 🗂️  
- Set up **user roles** and secure network access 🔐  
- Used **ADS SDK** to load data quickly and prepare it for modeling  
**Example:** Connected an Object Storage bucket and pulled data straight into a Jupyter notebook using `ads.dataset.factory`. Felt very smooth!

---

### 2️⃣ Machine Learning Lifecycle on OCI
- 🧹 **Data Prep:** cleaned, transformed, and engineered features  
- 🤖 **Training:** built models with XGBoost & scikit-learn  
- ✅ **Evaluation:** checked accuracy, ROC-AUC, and validated results  
- 🚀 **Deployment:** exposed models as REST endpoints for live predictions  
**Example:** Built a churn prediction model, deployed it, and tested predictions right from the notebook — super cool!

---

### 3️⃣ MLOps & Automation
- Built **pipelines** that retrain models automatically when new data arrives  
- Set up **model monitoring** to catch accuracy drops 📉  
- Learned how to version models and keep workflows reproducible  
**Example:** Configured a monitoring job that triggers an alert if model accuracy goes below a certain threshold.

---

### 4️⃣ OCI Service Integrations
- 🔐 **OCI Vault** – managed keys & secrets safely  
- ☁️ **Object Storage** – stored data and model artifacts  
- ⚡ **OCI Data Flow** – ran big data prep jobs at scale  
- 🏷️ **OCI Data Labeling** – created labeled datasets for training  
This gave me confidence in building a **secure, production-ready ML pipeline**.

---

### 5️⃣ Best Practices & Business Use
- Learned **cloud security best practices** (IAM, encryption, access control)  
- Optimized for **scalability & cost** using flexible compute options  
- Mapped ML solutions to **real business problems** like churn prediction, forecasting, and NLP  

---

## 🚀 Why This Matters

This was not just theory — it was fully **hands-on**.  
Now I can:
- Build **end-to-end ML pipelines** on OCI  
- Automate retraining and monitoring with MLOps 🛠️  
- Deliver **real-world solutions** for businesses with confidence  

---

## 🛠 Tech & Tools I Used
`OCI Data Science Workspaces`, `ADS SDK`, `XGBoost`, `scikit-learn`,  
`OCI Vault`, `Object Storage`, `Data Flow`, `Data Labeling`,  
`OCI Logging & Monitoring`, `REST APIs` for model deployment
